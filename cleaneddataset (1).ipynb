{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c6e44e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('cleaned_nifty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc45248",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Split Size= 80:20\n",
      "MSE: 4.804405282375961\n",
      "MDAPE: 17.089167355908465\n",
      "Accuracy: 82.91083264409153\n",
      "\n",
      "Model: Ridge Regression\n",
      "Split Size= 80:20\n",
      "MSE: 2.296241820092828\n",
      "MDAPE: 13.029696799178863\n",
      "Accuracy: 86.97030320082114\n",
      "\n",
      "Model: Lasso Regression\n",
      "Split Size= 80:20\n",
      "MSE: 2.0963941157179393\n",
      "MDAPE: 10.26447416333147\n",
      "Accuracy: 89.73552583666853\n",
      "\n",
      "Model: ElasticNet Regression\n",
      "Split Size= 80:20\n",
      "MSE: 21.31685907760745\n",
      "MDAPE: 27.68760227303201\n",
      "Accuracy: 72.31239772696799\n",
      "\n",
      "Model: Decision Tree Regressor\n",
      "Split Size= 80:20\n",
      "MSE: 919.1478199999999\n",
      "MDAPE: 264.33959827160606\n",
      "Accuracy: -164.33959827160606\n",
      "\n",
      "Model: Random Forest Regressor\n",
      "Split Size= 80:20\n",
      "MSE: 454.52518987599996\n",
      "MDAPE: 191.80476324074155\n",
      "Accuracy: -91.80476324074155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "# You can add additional features or apply transformations to existing ones here\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df.drop(columns=['Year', 'Annual'])\n",
    "y = df['Annual']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Selection and Hyperparameter Tuning\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Linear Regression': {},\n",
    "    'Ridge Regression': {'model__alpha': [0.1, 1.0, 10.0]},  # Specify alpha for Ridge model\n",
    "    'Lasso Regression': {'model__alpha': [0.1, 1.0, 10.0]},  # Specify alpha for Lasso model\n",
    "    'ElasticNet Regression': {'model__alpha': [0.1, 1.0, 10.0], 'model__l1_ratio': [0.1, 0.5, 0.9]},  # Specify alpha and l1_ratio for ElasticNet model\n",
    "    'Decision Tree Regressor': {'model__max_depth': [None, 10, 20]},  # Specify max_depth for Decision Tree model\n",
    "    'Random Forest Regressor': {'model__n_estimators': [100, 200, 300], 'model__max_depth': [None, 10, 20]}  # Specify n_estimators and max_depth for Random Forest model\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Scale features\n",
    "        ('model', model)               # Model\n",
    "    ])\n",
    "    \n",
    "    # Grid search for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grids[model_name], cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model from grid search\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate models\n",
    "results = {}\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mdape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "    accuracy = 100 - mdape\n",
    "    \n",
    "    results[model_name] = {'MSE': mse, 'MDAPE': mdape, 'Accuracy': accuracy}\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Split Size= 80:20\")\n",
    "    print(f\"MSE: {metrics['MSE']}\")\n",
    "    print(f\"MDAPE: {metrics['MDAPE']}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9930a43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Split Size= 75:25\n",
      "MSE: 42.23090955523725\n",
      "MDAPE: 34.86714645434498\n",
      "Accuracy: 65.13285354565502\n",
      "\n",
      "Model: Ridge Regression\n",
      "Split Size= 75:25\n",
      "MSE: 10.528663953718945\n",
      "MDAPE: 16.828471957336042\n",
      "Accuracy: 83.17152804266397\n",
      "\n",
      "Model: Lasso Regression\n",
      "Split Size= 75:25\n",
      "MSE: 4.685744866673038\n",
      "MDAPE: 12.357690293588995\n",
      "Accuracy: 87.642309706411\n",
      "\n",
      "Model: ElasticNet Regression\n",
      "Split Size= 75:25\n",
      "MSE: 11.19596968046875\n",
      "MDAPE: 16.15452775971616\n",
      "Accuracy: 83.84547224028384\n",
      "\n",
      "Model: Decision Tree Regressor\n",
      "Split Size= 75:25\n",
      "MSE: 1208.7939999999999\n",
      "MDAPE: 297.66420269172806\n",
      "Accuracy: -197.66420269172806\n",
      "\n",
      "Model: Random Forest Regressor\n",
      "Split Size= 75:25\n",
      "MSE: 398.2966594083335\n",
      "MDAPE: 164.6858566280988\n",
      "Accuracy: -64.6858566280988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "# You can add additional features or apply transformations to existing ones here\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df.drop(columns=['Year', 'Annual'])\n",
    "y = df['Annual']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Model Selection and Hyperparameter Tuning\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Linear Regression': {},\n",
    "    'Ridge Regression': {'model__alpha': [0.1, 1.0, 10.0]},  # Specify alpha for Ridge model\n",
    "    'Lasso Regression': {'model__alpha': [0.1, 1.0, 10.0]},  # Specify alpha for Lasso model\n",
    "    'ElasticNet Regression': {'model__alpha': [0.1, 1.0, 10.0], 'model__l1_ratio': [0.1, 0.5, 0.9]},  # Specify alpha and l1_ratio for ElasticNet model\n",
    "    'Decision Tree Regressor': {'model__max_depth': [None, 10, 20]},  # Specify max_depth for Decision Tree model\n",
    "    'Random Forest Regressor': {'model__n_estimators': [100, 200, 300], 'model__max_depth': [None, 10, 20]}  # Specify n_estimators and max_depth for Random Forest model\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Scale features\n",
    "        ('model', model)               # Model\n",
    "    ])\n",
    "    \n",
    "    # Grid search for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grids[model_name], cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model from grid search\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate models\n",
    "results = {}\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mdape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "    accuracy = 100 - mdape\n",
    "    \n",
    "    results[model_name] = {'MSE': mse, 'MDAPE': mdape, 'Accuracy': accuracy}\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Split Size= 75:25\")\n",
    "    print(f\"MSE: {metrics['MSE']}\")\n",
    "    print(f\"MDAPE: {metrics['MDAPE']}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01c80f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Split Size= 70:30\n",
      "MSE: 39.23050619442212\n",
      "MDAPE: 38.11555342231291\n",
      "Accuracy: 61.88444657768709\n",
      "\n",
      "Model: Ridge Regression\n",
      "Split Size= 70:30\n",
      "MSE: 8.796828248676631\n",
      "MDAPE: 22.697339881668597\n",
      "Accuracy: 77.3026601183314\n",
      "\n",
      "Model: Lasso Regression\n",
      "Split Size= 70:30\n",
      "MSE: 92.33772798124461\n",
      "MDAPE: 43.46696952731785\n",
      "Accuracy: 56.53303047268215\n",
      "\n",
      "Model: ElasticNet Regression\n",
      "Split Size= 70:30\n",
      "MSE: 13.504116675325047\n",
      "MDAPE: 27.890202841243372\n",
      "Accuracy: 72.10979715875663\n",
      "\n",
      "Model: Decision Tree Regressor\n",
      "Split Size= 70:30\n",
      "MSE: 685.6442142857143\n",
      "MDAPE: 195.7231129279306\n",
      "Accuracy: -95.7231129279306\n",
      "\n",
      "Model: Random Forest Regressor\n",
      "Split Size= 70:30\n",
      "MSE: 341.0154535907145\n",
      "MDAPE: 146.59657889107567\n",
      "Accuracy: -46.596578891075666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "# You can add additional features or apply transformations to existing ones here\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df.drop(columns=['Year', 'Annual'])\n",
    "y = df['Annual']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model Selection and Hyperparameter Tuning\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Linear Regression': {},\n",
    "    'Ridge Regression': {'model__alpha': [0.1, 1.0, 10.0]},  # Specify alpha for Ridge model\n",
    "    'Lasso Regression': {'model__alpha': [0.1, 1.0, 10.0]},  # Specify alpha for Lasso model\n",
    "    'ElasticNet Regression': {'model__alpha': [0.1, 1.0, 10.0], 'model__l1_ratio': [0.1, 0.5, 0.9]},  # Specify alpha and l1_ratio for ElasticNet model\n",
    "    'Decision Tree Regressor': {'model__max_depth': [None, 10, 20]},  # Specify max_depth for Decision Tree model\n",
    "    'Random Forest Regressor': {'model__n_estimators': [100, 200, 300], 'model__max_depth': [None, 10, 20]}  # Specify n_estimators and max_depth for Random Forest model\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Scale features\n",
    "        ('model', model)               # Model\n",
    "    ])\n",
    "    \n",
    "    # Grid search for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grids[model_name], cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model from grid search\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate models\n",
    "results = {}\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mdape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "    accuracy = 100 - mdape\n",
    "    \n",
    "    results[model_name] = {'MSE': mse, 'MDAPE': mdape, 'Accuracy': accuracy}\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Split Size= 70:30\")\n",
    "    print(f\"MSE: {metrics['MSE']}\")\n",
    "    print(f\"MDAPE: {metrics['MDAPE']}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "split size=80-20\n",
    "Model: Linear Regression\n",
    "MSE: 4.804405282375961\n",
    "MDAPE: 17.089167355908465\n",
    "Accuracy: 82.91083264409153\n",
    "\n",
    "Model: Ridge Regression\n",
    "MSE: 2.296241820092828\n",
    "MDAPE: 13.029696799178863\n",
    "Accuracy: 86.97030320082114\n",
    "\n",
    "Model: Lasso Regression\n",
    "MSE: 2.0963941157179393\n",
    "MDAPE: 10.26447416333147\n",
    "Accuracy: 89.73552583666853\n",
    "\n",
    "Model: ElasticNet Regression\n",
    "MSE: 21.31685907760745\n",
    "MDAPE: 27.68760227303201\n",
    "Accuracy: 72.31239772696799\n",
    "\n",
    "Model: Decision Tree Regressor\n",
    "MSE: 888.4759799999998\n",
    "MDAPE: 307.80287184574473\n",
    "Accuracy: -207.80287184574473\n",
    "\n",
    "Model: Random Forest Regressor\n",
    "MSE: 424.46569717066706\n",
    "MDAPE: 191.343304500251\n",
    "Accuracy: -91.34330450025101\n",
    " \n",
    "split size=75-25\n",
    "Model: Linear Regression\n",
    "MSE: 42.23090955523725\n",
    "MDAPE: 34.86714645434498\n",
    "Accuracy: 65.13285354565502\n",
    "\n",
    "Model: Ridge Regression\n",
    "MSE: 10.528663953718945\n",
    "MDAPE: 16.828471957336042\n",
    "Accuracy: 83.17152804266397\n",
    "\n",
    "Model: Lasso Regression\n",
    "MSE: 4.685744866673038\n",
    "MDAPE: 12.357690293588995\n",
    "Accuracy: 87.642309706411\n",
    "\n",
    "Model: ElasticNet Regression\n",
    "MSE: 11.19596968046875\n",
    "MDAPE: 16.15452775971616\n",
    "Accuracy: 83.84547224028384\n",
    "\n",
    "Model: Decision Tree Regressor\n",
    "MSE: 792.9035\n",
    "MDAPE: 226.88579070995334\n",
    "Accuracy: -126.88579070995334\n",
    "\n",
    "Model: Random Forest Regressor\n",
    "MSE: 392.69976370750015\n",
    "MDAPE: 163.2322500193431\n",
    "Accuracy: -63.2322500193431\n",
    "\n",
    "split size=70-30\n",
    "Model: Linear Regression\n",
    "MSE: 39.23050619442212\n",
    "MDAPE: 38.11555342231291\n",
    "Accuracy: 61.88444657768709\n",
    "\n",
    "Model: Ridge Regression\n",
    "MSE: 8.796828248676631\n",
    "MDAPE: 22.697339881668597\n",
    "Accuracy: 77.3026601183314\n",
    "\n",
    "Model: Lasso Regression\n",
    "MSE: 92.33772798124461\n",
    "MDAPE: 43.46696952731785\n",
    "Accuracy: 56.53303047268215\n",
    "\n",
    "Model: ElasticNet Regression\n",
    "MSE: 13.504116675325047\n",
    "MDAPE: 27.890202841243372\n",
    "Accuracy: 72.10979715875663\n",
    "\n",
    "Model: Decision Tree Regressor\n",
    "MSE: 817.1634857142857\n",
    "MDAPE: 238.77062034313767\n",
    "Accuracy: -138.77062034313767\n",
    "\n",
    "Model: Random Forest Regressor\n",
    "MSE: 294.5530567914287\n",
    "MDAPE: 150.5291345545939\n",
    "Accuracy: -50.529134554593895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7cab8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
